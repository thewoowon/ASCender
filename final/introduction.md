1. 서론 (Introduction)

Transformer는 현재 자연어 처리, 코드, 멀티모달 작업 전반에서 사실상 표준 아키텍처로 자리잡았다. 그 핵심 구성 요소인 **스케일 내적 기반 자기어텐션(scaled dot-product self-attention)**은 전역적인 수용 범위(global receptive field)와 안정적인 최적화 특성을 제공하지만, 세 가지 한계를 여전히 보인다. 즉, (i) 모든 토큰 쌍을 무차별적으로 고려함으로써 발생하는 비효율성, **(ii) 토큰 간 의존성을 과제에 적합한 지역적 구조로 이끄는 **구조적 사전 지식(structural prior)의 부족, (iii) 어텐션 가중치가 광범위하게 분산되거나 비관련 패턴에 매달리면서 나타나는 해석 가능성의 한계이다. 기존 연구에서는 상대적 위치 정보, 국소성(locality) 제약, 희소성(sparsity) 패턴, 그래프 기반 바이어스 등 다양한 귀납적 편향(inductive bias)을 주입하려는 시도가 있었으나, 대부분은 특정 과제에 국한되거나 도메인 전반에 걸쳐 안정적으로 확장되기 어려운 한계를 가진다.

우리는 이러한 문제를 해결하기 위해 ASCender를 제안한다. ASCender는 자기어텐션에 보이드(Boids) 모델에서 영감을 받은 세 가지 편향—정렬(alignment), 분리(separation), 응집(cohesion)—을 주입한다. 이는 떼를 지어 움직이는 군집 행동에서 비롯된 단순한 지역 규칙으로, 토큰을 (a) 의미적으로 유사한 “방향”을 가진 이웃과 정렬시키고, (b) 과도하게 밀집되거나 중복된 이웃으로부터는 멀어지도록 하며, (c) 과제 관련 토큰 중심으로 응집되도록 이끈다. ASCender는 기존 어텐션을 대체하지 않고, 편향 행렬을 로짓(logit)에 가산하는 방식으로 동작한다. 이를 통해 기존 Transformer의 표현력은 유지하면서, 토큰 간 관계를 유용한 구조적 기하학으로 유도한다. 결과적으로 ASCender는 (1) 해석 가능성(emergent한 군집 패턴), (2) 데이터 효율성(불필요한 장거리 활성화 감소), (3) 강인성(중복 억제와 잡음 완화) 측면에서 개선을 추구한다.

우리는 **풀 팩토리얼 설계(full factorial design)**를 통해 ASCender를 체계적으로 평가한다. 여기에는 편향 강도 (\beta_\mathrm{A}, \beta_\mathrm{S}, \beta_\mathrm{C}), 이웃 정의 방식(반경 기반, k-NN, 하이브리드), 헤드 수, 층 수, 모델 차원, 학습 예산 등을 모두 교차 실험한다. 실험은 추론(reasoning), 장기 의존(long-range dependency), **생성 품질(generation quality)**을 요구하는 벤치마크를 대상으로 진행되었다. [DATASET-A], [DATASET-B], [DATASET-C] 전반에서 ASCender는 동등 규모의 Transformer 대비 [+X.X] EM/F1 향상, [−Y.Y] ECE 개선, 엔트로피 감소 및 [Z%] 계산 효율 이득을 보여주었다. 정성적 분석에서는 정렬에 의해 형성된 의미적 ‘레인(lane)’, 분리에 따른 희소성 확보, 응집에 따른 담화 연속성이 드러났으며, 이는 모델 해석 가능성 주장을 뒷받침한다. 감도 분석(sensitivity analysis)은 \beta 값이 지나치게 커질 경우 성능이 오히려 저하되는 U자형 곡선 패턴을 확인하였고, 특정 β 구간에서는 다양한 데이터셋에 걸쳐 안정적으로 성능이 유지됨을 보였다.

연구 질문. 본 연구는 다음 세 가지 질문에 답하고자 한다:
	•	RQ1 (구조): 단순한 지역 규칙이 정확도 손실 없이 안정적이고 해석 가능한 어텐션 구조를 유도할 수 있는가?
	•	RQ2 (효율성): 이러한 편향이 불필요한 장거리 상호작용을 줄여 계산 대비 성능 효율성을 개선할 수 있는가?
	•	RQ3 (일반화): 성능 개선이 과제와 규모 전반에서 견고하게 유지되며, 편향 강도 및 이웃 정의 방식에 대한 민감도는 어떠한가?

설계 원칙. ASCender는 세 가지 원칙에 따른다: (P1) 호환성—어떤 어텐션 계층에도 모듈식으로 적용 가능, (P2) 약한 사전 지식—편향은 부드럽고 가변적이며 학습 가능한 계수로 제어, (P3) 최소한의 복잡성—표준 커널을 그대로 사용, 추가적인 커스텀 연산 없이 구현.

접근 개요. 기존 어텐션을 A=\mathrm{softmax}((QK^\top)/\sqrt{d_k})라 할 때, ASCender는 다음과 같이 계산된다:
A’=\mathrm{softmax}\!\Big(\tfrac{QK^\top}{\sqrt{d_k}}+\beta_\mathrm{A}B_\mathrm{align}+\beta_\mathrm{S}B_\mathrm{sep}+\beta_\mathrm{C}B_\mathrm{coh}\Big).

여기서 각 B_{\cdot}는 토큰 임베딩과 위치 관계를 기반으로 계산된 지역적 상호작용 잠재치(potential)이며, 실험에서는 이웃 정의, 헤딩 벡터, 거리 메트릭 등 다양한 요인을 교차 분석한다.

연구 결과 요약. ASCender는 다수의 설정에서 Transformer 대비 **[주요 성능 지표 향상 범위]**를 달성했으며, 어텐션 엔트로피 평균 [Δ 감소], **보정 오류(ECE) [Δ 개선]**를 보였다. 시각적 분석에서는 정렬 기반 의미적 경로, 분리 기반 희소성 확보, 응집 기반 담화 연쇄가 나타났다. 이는 Boids 원리를 자기어텐션에 접목한 본 모델의 해석 가능성과 구조적 효과를 뒷받침한다.

논문 구성. 2장에서는 관련 연구를 검토한다. 4장은 Transformer와 Boids의 배경을 다룬다. 5장은 ASCender 모델을 정식화한다. 6장은 실험 설계, 7장은 결과 및 분석을, 8장은 함의·한계·윤리적 고려를 다룬다. 마지막 9장에서 결론을 제시한다.

⸻

1.1 기여 (Contributions)
	1.	군집 지능 기반 어텐션 편향 제안. 자기어텐션 로짓에 추가할 수 있는 정렬, 분리, 응집 편향을 제안한다. 이는 기존 구조를 그대로 유지하면서도 간단히 결합 가능한 모듈로 설계되었다.
	2.	통합 수학적 정식화. 각 편향을 헤딩 유사도, 지역 밀집도, 중심점 거리로 정의된 잠재치로 수식화하고, 헤드 단위로 학습 가능한 계수 \beta를 부여한다.
	3.	풀 팩토리얼 평가. 편향 강도, 이웃 정의, 모델 규모, 학습 예산을 교차 평가하는 체계적 민감도 분석을 통해 ASCender의 효과와 요인 간 상호작용을 검증한다.
	4.	해석 가능성과 보정 개선. ASCender는 군집-유사 어텐션 지도, 낮은 어텐션 엔트로피, **개선된 확률 보정(ECE, NLL)**을 보여, 약한 구조적 사전이 토큰 기하학을 형성하는데 효과적임을 입증한다.
	5.	효율성 개선. 기존 Transformer 커널(예: FlashAttention)과 완전히 호환되며, 별도 커널 수정 없이 계산 대비 성능 효율을 향상한다.
	6.	어블레이션 및 진단. 세 가지 편향을 개별적으로 혹은 조합하여 평가하고, 희소성 지표, 중복도, 군집 지속성 등을 분석하여 각 편향의 기능적 기여와 안정적인 β 범위를 제시한다.
	7.	오픈 리소스 제공. ASCender 코드, 실험 설정, 시각화 도구(어텐션 맵, 이웃 히트맵, β 민감도 대시보드)를 공개하여 재현성과 후속 연구를 지원한다.
